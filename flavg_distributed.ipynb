{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Distributed Federated Learning with Boston Housing Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Importing the libraries</b>\n",
    "\n",
    "<ul>\n",
    "<li> Pytorch (to train the model)\n",
    "<li> Pysyft (to train using federated approach)\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "from syft.frameworks.torch.fl import utils\n",
    "from syft.workers.websocket_client import WebsocketClientWorker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c81e82d5d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.epochs = 50\n",
    "        self.lr = 0.001\n",
    "        self.test_batch_size = 8\n",
    "        self.batch_size = 8\n",
    "        self.log_interval = 10\n",
    "        self.seed = 1\n",
    "        self.weight_scale = 0.03\n",
    "    \n",
    "args = Parser()\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data Preprocessing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/boston_housing.pickle','rb') as f:\n",
    "    ((x, y), (x_test, y_test)) = pickle.load(f)\n",
    "\n",
    "x = torch.from_numpy(x).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x.mean(0, keepdim=True)\n",
    "dev = x.std(0, keepdim=True)\n",
    "mean[:, 3] = 0.\n",
    "dev[:, 3] = 1.\n",
    "x = (x - mean) / dev\n",
    "x_test = (x_test - mean) / dev\n",
    "train = TensorDataset(x, y)\n",
    "test = TensorDataset(x_test, y_test)\n",
    "train_loader = DataLoader(train, batch_size=args.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=args.test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating architecture of the Neural Network model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 32)\n",
    "        self.fc2 = nn.Linear(32, 24)\n",
    "        self.fc4 = nn.Linear(24, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def federated_avg(self, neighbour_model_params=None, current_worker=None):\n",
    "        #Average two models weights\n",
    "        \n",
    "        params1 = self.state_dict()\n",
    "        params2 = neighbour_model_params.copy()\n",
    "      \n",
    "        with torch.no_grad():\n",
    "            for name1 in params1:\n",
    "                if name1 in params2:\n",
    "                    neighbour_ptr = params2[name1].copy()\n",
    "                    neighbour_ptr.move(current_worker)\n",
    "                    #print(current_worker, neighbour_ptr)\n",
    "                    params1[name1] = (params1[name1]  +  neighbour_ptr)/2\n",
    "        \n",
    "                    \n",
    "        self.load_state_dict(params1, strict=False)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Connect to the workers or the devices for training</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "bob_worker = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice_worker = sy.VirtualWorker(hook, id=\"alice\")\n",
    "charlie_worker = sy.VirtualWorker(hook, id=\"charlie\")\n",
    "# kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook}\n",
    "# alice = WebsocketClientWorker(id='alice', port=8779, **kwargs_websocket)\n",
    "# bob = WebsocketClientWorker(id='bob', port=8778, **kwargs_websocket)\n",
    "compute_nodes = [bob_worker, alice_worker, charlie_worker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Though data will be available offline for federated learning with the workers but here we are sending the data over to the workers for training with ondevice capability</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_dataset = (list(), list(), list())\n",
    "train_distributed_dataset = []\n",
    "\n",
    "for batch_idx, (data,target) in enumerate(train_loader):\n",
    "    data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "    target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "    remote_dataset[batch_idx % len(compute_nodes)].append((data, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remote_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model = Net()\n",
    "alices_model = Net()\n",
    "charlie_model = Net()\n",
    "bobs_optimizer = optim.SGD(bobs_model.parameters(), lr=args.lr)\n",
    "alices_optimizer = optim.SGD(alices_model.parameters(), lr=args.lr)\n",
    "charlie_optimizer = optim.SGD(charlie_model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [bobs_model, alices_model, charlie_model]\n",
    "optimizers = [bobs_optimizer, alices_optimizer, charlie_optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=13, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=24, bias=True)\n",
       "  (fc4): Linear(in_features=24, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_events(eventsfile):\n",
    "    eventsdf = pd.read_csv(eventsfile, index_col=0)\n",
    "    return eventsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id1</th>\n",
       "      <th>worker_id2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batchnum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          worker_id1  worker_id2\n",
       "batchnum                        \n",
       "0                  1           2\n",
       "1                  2           3\n",
       "2                  1           3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventsdf = read_events(\"three_worker_events.csv\")\n",
    "eventsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(data, target, model, optimizer):\n",
    "    model.send(data.location)\n",
    "    #print(model, data)\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(data)\n",
    "    loss = F.mse_loss(prediction.view(-1), target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def exchange_parameters(models, data_index):\n",
    "    #Get the workers ID from event dataframe to exchange parameters between two worker models.\n",
    "    event_idx = data_index % len(eventsdf)\n",
    "    event_row = eventsdf.loc[[event_idx]]\n",
    "    worker_id1 = event_row['worker_id1'].values[0]-1\n",
    "    worker_id2 = event_row['worker_id2'].values[0]-1\n",
    "    worker1_model = models[worker_id1]\n",
    "    worker2_model = models[worker_id2]\n",
    "    worker1_params = worker1_model.state_dict()\n",
    "    worker2_params = worker2_model.state_dict()\n",
    "    \n",
    "    #Send worker2 params to worker1 for averaging at worker1\n",
    "    worker1_model.federated_avg(worker2_params, compute_nodes[worker_id1])\n",
    "    \n",
    "    #Send worker1 params to worker2 for averaging at worker2\n",
    "    worker2_model.federated_avg(worker1_params, compute_nodes[worker_id2])\n",
    "    \n",
    "    \n",
    "\n",
    "def train():\n",
    "    for data_index in range(len(remote_dataset[0])-1):\n",
    "        #print(f\"Trip {data_index}\")\n",
    "        for remote_index in range(len(compute_nodes)):\n",
    "            data, target = remote_dataset[remote_index][data_index]\n",
    "            models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])\n",
    "           \n",
    "        #Exchange of parameter between two remote models.\n",
    "        exchange_parameters(models, data_index)\n",
    "        \n",
    "        for model in models:\n",
    "            model.get()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(worker_node, federated_model):\n",
    "    federated_model.eval()\n",
    "    test_loss = 0\n",
    "    for data, target in test_loader:\n",
    "        output = federated_model(data)\n",
    "        test_loss += F.mse_loss(output.view(-1), target, reduction='sum').item()\n",
    "        predection = output.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set for worker {}: Average loss: {:.4f}'.format(worker_node.id, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number 1\n",
      "Test set for worker bob: Average loss: 584.5751\n",
      "Test set for worker alice: Average loss: 584.5274\n",
      "Test set for worker charlie: Average loss: 584.5947\n",
      "Communication time over the network 1.59 s\n",
      "\n",
      "Epoch Number 2\n",
      "Test set for worker bob: Average loss: 536.6637\n",
      "Test set for worker alice: Average loss: 536.5852\n",
      "Test set for worker charlie: Average loss: 536.6685\n",
      "Communication time over the network 1.64 s\n",
      "\n",
      "Epoch Number 3\n",
      "Test set for worker bob: Average loss: 421.7588\n",
      "Test set for worker alice: Average loss: 421.5169\n",
      "Test set for worker charlie: Average loss: 421.1362\n",
      "Communication time over the network 1.69 s\n",
      "\n",
      "Epoch Number 4\n",
      "Test set for worker bob: Average loss: 44.6196\n",
      "Test set for worker alice: Average loss: 45.4724\n",
      "Test set for worker charlie: Average loss: 47.3344\n",
      "Communication time over the network 1.6 s\n",
      "\n",
      "Epoch Number 5\n",
      "Test set for worker bob: Average loss: 21.3561\n",
      "Test set for worker alice: Average loss: 22.1148\n",
      "Test set for worker charlie: Average loss: 23.1130\n",
      "Communication time over the network 1.66 s\n",
      "\n",
      "Epoch Number 6\n",
      "Test set for worker bob: Average loss: 18.5862\n",
      "Test set for worker alice: Average loss: 19.2822\n",
      "Test set for worker charlie: Average loss: 20.2522\n",
      "Communication time over the network 1.74 s\n",
      "\n",
      "Epoch Number 7\n",
      "Test set for worker bob: Average loss: 18.5081\n",
      "Test set for worker alice: Average loss: 19.5988\n",
      "Test set for worker charlie: Average loss: 20.1752\n",
      "Communication time over the network 1.7 s\n",
      "\n",
      "Epoch Number 8\n",
      "Test set for worker bob: Average loss: 18.5496\n",
      "Test set for worker alice: Average loss: 19.6132\n",
      "Test set for worker charlie: Average loss: 20.6296\n",
      "Communication time over the network 1.63 s\n",
      "\n",
      "Epoch Number 9\n",
      "Test set for worker bob: Average loss: 18.5744\n",
      "Test set for worker alice: Average loss: 19.5165\n",
      "Test set for worker charlie: Average loss: 20.9752\n",
      "Communication time over the network 1.57 s\n",
      "\n",
      "Epoch Number 10\n",
      "Test set for worker bob: Average loss: 18.5411\n",
      "Test set for worker alice: Average loss: 19.3936\n",
      "Test set for worker charlie: Average loss: 21.1269\n",
      "Communication time over the network 1.61 s\n",
      "\n",
      "Epoch Number 11\n",
      "Test set for worker bob: Average loss: 18.6502\n",
      "Test set for worker alice: Average loss: 19.4370\n",
      "Test set for worker charlie: Average loss: 21.2328\n",
      "Communication time over the network 1.65 s\n",
      "\n",
      "Epoch Number 12\n",
      "Test set for worker bob: Average loss: 18.7672\n",
      "Test set for worker alice: Average loss: 19.5193\n",
      "Test set for worker charlie: Average loss: 21.2574\n",
      "Communication time over the network 1.78 s\n",
      "\n",
      "Epoch Number 13\n",
      "Test set for worker bob: Average loss: 18.8035\n",
      "Test set for worker alice: Average loss: 19.3936\n",
      "Test set for worker charlie: Average loss: 21.3188\n",
      "Communication time over the network 1.72 s\n",
      "\n",
      "Epoch Number 14\n",
      "Test set for worker bob: Average loss: 18.9666\n",
      "Test set for worker alice: Average loss: 19.4843\n",
      "Test set for worker charlie: Average loss: 21.3657\n",
      "Communication time over the network 1.63 s\n",
      "\n",
      "Epoch Number 15\n",
      "Test set for worker bob: Average loss: 19.1172\n",
      "Test set for worker alice: Average loss: 19.5277\n",
      "Test set for worker charlie: Average loss: 21.3837\n",
      "Communication time over the network 1.61 s\n",
      "\n",
      "Epoch Number 16\n",
      "Test set for worker bob: Average loss: 19.3651\n",
      "Test set for worker alice: Average loss: 19.7986\n",
      "Test set for worker charlie: Average loss: 21.4212\n",
      "Communication time over the network 1.63 s\n",
      "\n",
      "Epoch Number 17\n",
      "Test set for worker bob: Average loss: 19.3911\n",
      "Test set for worker alice: Average loss: 19.6136\n",
      "Test set for worker charlie: Average loss: 21.4253\n",
      "Communication time over the network 1.72 s\n",
      "\n",
      "Epoch Number 18\n",
      "Test set for worker bob: Average loss: 19.6594\n",
      "Test set for worker alice: Average loss: 20.0010\n",
      "Test set for worker charlie: Average loss: 21.3429\n",
      "Communication time over the network 1.64 s\n",
      "\n",
      "Epoch Number 19\n",
      "Test set for worker bob: Average loss: 19.9406\n",
      "Test set for worker alice: Average loss: 20.3955\n",
      "Test set for worker charlie: Average loss: 21.3752\n",
      "Communication time over the network 1.61 s\n",
      "\n",
      "Epoch Number 20\n",
      "Test set for worker bob: Average loss: 19.9152\n",
      "Test set for worker alice: Average loss: 20.0782\n",
      "Test set for worker charlie: Average loss: 21.5138\n",
      "Communication time over the network 1.63 s\n",
      "\n",
      "Epoch Number 21\n",
      "Test set for worker bob: Average loss: 20.3667\n",
      "Test set for worker alice: Average loss: 20.8968\n",
      "Test set for worker charlie: Average loss: 21.4868\n",
      "Communication time over the network 1.67 s\n",
      "\n",
      "Epoch Number 22\n",
      "Test set for worker bob: Average loss: 20.3215\n",
      "Test set for worker alice: Average loss: 20.6176\n",
      "Test set for worker charlie: Average loss: 21.6373\n",
      "Communication time over the network 1.64 s\n",
      "\n",
      "Epoch Number 23\n",
      "Test set for worker bob: Average loss: 20.6362\n",
      "Test set for worker alice: Average loss: 21.1187\n",
      "Test set for worker charlie: Average loss: 21.6134\n",
      "Communication time over the network 1.76 s\n",
      "\n",
      "Epoch Number 24\n",
      "Test set for worker bob: Average loss: 20.4894\n",
      "Test set for worker alice: Average loss: 20.6974\n",
      "Test set for worker charlie: Average loss: 21.6853\n",
      "Communication time over the network 1.67 s\n",
      "\n",
      "Epoch Number 25\n",
      "Test set for worker bob: Average loss: 20.3669\n",
      "Test set for worker alice: Average loss: 20.4339\n",
      "Test set for worker charlie: Average loss: 21.6345\n",
      "Communication time over the network 1.67 s\n",
      "\n",
      "Epoch Number 26\n",
      "Test set for worker bob: Average loss: 20.4574\n",
      "Test set for worker alice: Average loss: 20.6085\n",
      "Test set for worker charlie: Average loss: 21.5409\n",
      "Communication time over the network 1.76 s\n",
      "\n",
      "Epoch Number 27\n",
      "Test set for worker bob: Average loss: 20.6750\n",
      "Test set for worker alice: Average loss: 20.9985\n",
      "Test set for worker charlie: Average loss: 21.4835\n",
      "Communication time over the network 1.78 s\n",
      "\n",
      "Epoch Number 28\n",
      "Test set for worker bob: Average loss: 20.3102\n",
      "Test set for worker alice: Average loss: 20.3346\n",
      "Test set for worker charlie: Average loss: 21.4432\n",
      "Communication time over the network 1.71 s\n",
      "\n",
      "Epoch Number 29\n",
      "Test set for worker bob: Average loss: 20.6046\n",
      "Test set for worker alice: Average loss: 20.9442\n",
      "Test set for worker charlie: Average loss: 21.3113\n",
      "Communication time over the network 1.74 s\n",
      "\n",
      "Epoch Number 30\n",
      "Test set for worker bob: Average loss: 20.7591\n",
      "Test set for worker alice: Average loss: 21.0924\n",
      "Test set for worker charlie: Average loss: 21.3991\n",
      "Communication time over the network 1.85 s\n",
      "\n",
      "Epoch Number 31\n",
      "Test set for worker bob: Average loss: 20.3363\n",
      "Test set for worker alice: Average loss: 20.3037\n",
      "Test set for worker charlie: Average loss: 21.4367\n",
      "Communication time over the network 1.72 s\n",
      "\n",
      "Epoch Number 32\n",
      "Test set for worker bob: Average loss: 20.6856\n",
      "Test set for worker alice: Average loss: 20.9600\n",
      "Test set for worker charlie: Average loss: 21.3250\n",
      "Communication time over the network 1.73 s\n",
      "\n",
      "Epoch Number 33\n",
      "Test set for worker bob: Average loss: 20.5442\n",
      "Test set for worker alice: Average loss: 20.6184\n",
      "Test set for worker charlie: Average loss: 21.4228\n",
      "Communication time over the network 1.72 s\n",
      "\n",
      "Epoch Number 34\n",
      "Test set for worker bob: Average loss: 20.5376\n",
      "Test set for worker alice: Average loss: 20.6811\n",
      "Test set for worker charlie: Average loss: 21.2932\n",
      "Communication time over the network 1.69 s\n",
      "\n",
      "Epoch Number 35\n",
      "Test set for worker bob: Average loss: 20.7562\n",
      "Test set for worker alice: Average loss: 21.0865\n",
      "Test set for worker charlie: Average loss: 21.2231\n",
      "Communication time over the network 1.63 s\n",
      "\n",
      "Epoch Number 36\n",
      "Test set for worker bob: Average loss: 20.1854\n",
      "Test set for worker alice: Average loss: 20.1256\n",
      "Test set for worker charlie: Average loss: 21.1541\n",
      "Communication time over the network 1.59 s\n",
      "\n",
      "Epoch Number 37\n",
      "Test set for worker bob: Average loss: 20.3708\n",
      "Test set for worker alice: Average loss: 20.5703\n",
      "Test set for worker charlie: Average loss: 21.0090\n",
      "Communication time over the network 1.59 s\n",
      "\n",
      "Epoch Number 38\n",
      "Test set for worker bob: Average loss: 20.3903\n",
      "Test set for worker alice: Average loss: 20.5760\n",
      "Test set for worker charlie: Average loss: 20.9802\n",
      "Communication time over the network 1.71 s\n",
      "\n",
      "Epoch Number 39\n",
      "Test set for worker bob: Average loss: 20.1003\n",
      "Test set for worker alice: Average loss: 20.0812\n",
      "Test set for worker charlie: Average loss: 21.0120\n",
      "Communication time over the network 1.84 s\n",
      "\n",
      "Epoch Number 40\n",
      "Test set for worker bob: Average loss: 20.4485\n",
      "Test set for worker alice: Average loss: 20.7263\n",
      "Test set for worker charlie: Average loss: 20.9067\n",
      "Communication time over the network 1.7 s\n",
      "\n",
      "Epoch Number 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set for worker bob: Average loss: 20.3979\n",
      "Test set for worker alice: Average loss: 20.6635\n",
      "Test set for worker charlie: Average loss: 20.8650\n",
      "Communication time over the network 1.78 s\n",
      "\n",
      "Epoch Number 42\n",
      "Test set for worker bob: Average loss: 20.4586\n",
      "Test set for worker alice: Average loss: 20.7691\n",
      "Test set for worker charlie: Average loss: 20.8586\n",
      "Communication time over the network 1.72 s\n",
      "\n",
      "Epoch Number 43\n",
      "Test set for worker bob: Average loss: 20.0111\n",
      "Test set for worker alice: Average loss: 19.9907\n",
      "Test set for worker charlie: Average loss: 20.9072\n",
      "Communication time over the network 1.66 s\n",
      "\n",
      "Epoch Number 44\n",
      "Test set for worker bob: Average loss: 20.2678\n",
      "Test set for worker alice: Average loss: 20.5576\n",
      "Test set for worker charlie: Average loss: 20.5964\n",
      "Communication time over the network 1.65 s\n",
      "\n",
      "Epoch Number 45\n",
      "Test set for worker bob: Average loss: 20.1979\n",
      "Test set for worker alice: Average loss: 20.3918\n",
      "Test set for worker charlie: Average loss: 20.7355\n",
      "Communication time over the network 1.78 s\n",
      "\n",
      "Epoch Number 46\n",
      "Test set for worker bob: Average loss: 20.2606\n",
      "Test set for worker alice: Average loss: 20.5121\n",
      "Test set for worker charlie: Average loss: 20.6863\n",
      "Communication time over the network 1.8 s\n",
      "\n",
      "Epoch Number 47\n",
      "Test set for worker bob: Average loss: 19.7826\n",
      "Test set for worker alice: Average loss: 19.7242\n",
      "Test set for worker charlie: Average loss: 20.6514\n",
      "Communication time over the network 1.73 s\n",
      "\n",
      "Epoch Number 48\n",
      "Test set for worker bob: Average loss: 19.9523\n",
      "Test set for worker alice: Average loss: 20.0851\n",
      "Test set for worker charlie: Average loss: 20.4876\n",
      "Communication time over the network 1.62 s\n",
      "\n",
      "Epoch Number 49\n",
      "Test set for worker bob: Average loss: 19.9122\n",
      "Test set for worker alice: Average loss: 20.1196\n",
      "Test set for worker charlie: Average loss: 20.3903\n",
      "Communication time over the network 1.58 s\n",
      "\n",
      "Epoch Number 50\n",
      "Test set for worker bob: Average loss: 20.1069\n",
      "Test set for worker alice: Average loss: 20.3815\n",
      "Test set for worker charlie: Average loss: 20.4367\n",
      "Communication time over the network 1.63 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    start_time = time.time()\n",
    "    print(f\"Epoch Number {epoch + 1}\")\n",
    "    train()\n",
    "    \n",
    "    for node, model in zip(compute_nodes,models):\n",
    "        test(node, model)\n",
    "    total_time = time.time() - start_time\n",
    "    print('Communication time over the network', round(total_time, 2), 's\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
